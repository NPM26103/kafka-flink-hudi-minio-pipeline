services:
  # -------------------- Kafka (KRaft) --------------------
  broker:
    image: apache/kafka:3.7.0
    container_name: broker
    ports:
      - "29092:29092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@broker:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0

  # Create topics
  kafka_init:
    image: apache/kafka:3.7.0
    depends_on:
      - broker
    entrypoint: ["/bin/sh","-lc"]
    command: >
      "
      echo 'Waiting Kafka...'; sleep 3;
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server broker:9092 --create --if-not-exists --topic raw.student.csv --partitions 1 --replication-factor 1;
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server broker:9092 --create --if-not-exists --topic raw.student.http --partitions 1 --replication-factor 1;
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server broker:9092 --create --if-not-exists --topic output-topic --partitions 1 --replication-factor 1;
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server broker:9092 --create --if-not-exists --topic output-topic-dlq --partitions 1 --replication-factor 1;
      echo 'Kafka topics ready.';
      "
    restart: "no"

  # -------------------- MinIO (S3 for Hudi/Hive) --------------------
  minio:
    image: minio/minio:latest
    container_name: minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data

  minio_init:
    image: minio/mc:latest
    container_name: minio-init
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -lc "
      sleep 2;
      mc alias set local http://minio:9000 minioadmin minioadmin;
      mc mb -p local/hudi || true;
      mc anonymous set none local/hudi || true;
      echo 'MinIO bucket ready: hudi';
      "
    restart: "no"

  # -------------------- Flink --------------------
  jobmanager:
    build:
      context: ./docker/flink
    image: final-flink:1.18.1
    container_name: flink-jobmanager
    command: jobmanager
    ports:
      - "8081:8081"
    environment:
      HADOOP_CONF_DIR: /opt/flink/conf
      # optional: also provide env creds (some libs read env first)
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: jobmanager
        jobmanager.memory.process.size: 1600m
        parallelism.default: 1
        taskmanager.numberOfTaskSlots: 2
        state.backend: hashmap
        state.checkpoints.dir: file:///data/flink-checkpoints
        state.savepoints.dir: file:///data/flink-savepoints

        fs.s3a.endpoint: http://minio:9000
        fs.s3a.access.key: minioadmin
        fs.s3a.secret.key: minioadmin
        fs.s3a.path.style.access: true
        fs.s3a.connection.ssl.enabled: false
        fs.s3a.aws.credentials.provider: org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
        fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
        fs.AbstractFileSystem.s3a.impl: org.apache.hadoop.fs.s3a.S3A
    volumes:
      - ./docker/data:/data
    depends_on:
      - broker
      - kafka_init
      - minio
      - minio_init

  taskmanager1:
    image: final-flink:1.18.1
    command: taskmanager
    environment:
      HADOOP_CONF_DIR: /opt/flink/conf
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 2
        taskmanager.memory.process.size: 2000m

        fs.s3a.endpoint: http://minio:9000
        fs.s3a.access.key: minioadmin
        fs.s3a.secret.key: minioadmin
        fs.s3a.path.style.access: true
        fs.s3a.connection.ssl.enabled: false
        fs.s3a.aws.credentials.provider: org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
        fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
        fs.AbstractFileSystem.s3a.impl: org.apache.hadoop.fs.s3a.S3A
    volumes:
      - ./docker/data:/data
    depends_on:
      - jobmanager

  taskmanager2:
    image: final-flink:1.18.1
    command: taskmanager
    environment:
      HADOOP_CONF_DIR: /opt/flink/conf
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 2
        taskmanager.memory.process.size: 2000m

        fs.s3a.endpoint: http://minio:9000
        fs.s3a.access.key: minioadmin
        fs.s3a.secret.key: minioadmin
        fs.s3a.path.style.access: true
        fs.s3a.connection.ssl.enabled: false
        fs.s3a.aws.credentials.provider: org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
        fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
        fs.AbstractFileSystem.s3a.impl: org.apache.hadoop.fs.s3a.S3A
    volumes:
      - ./docker/data:/data
    depends_on:
      - jobmanager

  # -------------------- Auto-submit Flink transform job --------------------
  flink_job:
    image: final-flink:1.18.1
    container_name: flink-submit-flink
    environment:
      HADOOP_CONF_DIR: /opt/flink/conf
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
    depends_on:
      - jobmanager
      - taskmanager1
      - taskmanager2
      - broker
      - kafka_init
    command: ["/submit-flink.sh"]
    restart: "no"

  # -------------------- Auto-submit Hudi job --------------------
  hudi_job:
    image: final-flink:1.18.1
    container_name: flink-submit-hudi
    environment:
      HADOOP_CONF_DIR: /opt/flink/conf
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
    depends_on:
      - jobmanager
      - taskmanager1
      - taskmanager2
      - broker
      - kafka_init
      - minio_init
      # - hive-metastore
    command: ["/submit-hudi.sh"]
    restart: "no"

volumes:
  minio_data:
